{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "b0dbfb02-a527-4d3a-bab2-4df6f0f57c5a",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Study: Applying ML models to fraud detection on financial transactions\n",
        "Applying a decision tree based model (RandomForestClassifier) to classify financial transactions as fraud or non-fraud.\n",
        "\n",
        "The dataset used in this study is the **Synthetic Financial Datasets For Fraud Detection** https://www.kaggle.com/ealaxi/paysim1\n",
        "\n",
        "\n",
        "- **step**: maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).\n",
        "- **type**: CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.\n",
        "- **amount**: amount of the transaction in local currency.\n",
        "- **nameOrig**: customer who started the transaction\n",
        "- **oldbalanceOrg**: initial balance before the transaction\n",
        "- **newbalanceOrig**: new balance after the transaction\n",
        "- **nameDest**: customer who is the recipient of the transaction\n",
        "- **oldbalanceDest**: initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).\n",
        "- **newbalanceDest**: new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).\n",
        "- **isFraud**: This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control of customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.\n",
        "- **isFlaggedFraud**: The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "3a1da31a-443d-4da1-a17c-4d878c222cff",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c74dc542-6cff-4642-acc3-56cb57f69e0a",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "0d6e9f82-6685-425a-ab44-e474da60364c",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "fb8cdaf1-16ce-43da-b046-02d5cab6122d",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "SM_BASE_TRAIN = '../data/PS_20174392719_1491204439457_log.csv'\n",
        "\n",
        "df = pd.read_csv(SM_BASE_TRAIN)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "00544005-deb7-446c-9489-ddbd5cf976c0",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### Creating new features based on the dataset description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d6e12323-eb4e-478b-9d52-ddab2d582b64",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "# there is fraud only on TRANSFER and CASH_OUT, let's filter and try only with these types\n",
        "df_dataset = df.copy()\n",
        "df_dataset['hour'] = (df_dataset.step % 24)\n",
        "df_dataset['dayOfMonth'] = (df_dataset.step // 24) + 1\n",
        "df_dataset['signal'] = df_dataset.type.apply(lambda x: -1 if x == 'CASH_IN' else 1)\n",
        "df_dataset['currbalanceDest'] = df_dataset.oldbalanceDest + (df_dataset.signal * df_dataset.amount)\n",
        "df_dataset['isMerchantDest'] = df_dataset.nameDest.apply(lambda x: 1 if x.startswith('M') else 0)\n",
        "\n",
        "df_dataset.type = df_dataset.type.astype('category').cat.codes\n",
        "\n",
        "## After some analysis we can say that there are errors related to the balance \n",
        "## of both accounts after the transaction. Let's try to evidence it to the model\n",
        "df_dataset['errorBalanceOrig'] = df_dataset.newbalanceOrig + df_dataset.amount - df_dataset.oldbalanceOrg\n",
        "df_dataset['errorBalanceDest'] = df_dataset.oldbalanceDest + df_dataset.amount - df_dataset.newbalanceDest\n",
        "\n",
        "df_dataset = df_dataset.drop(columns=['step', 'nameOrig', 'nameDest', 'isFlaggedFraud', 'currbalanceDest', 'signal']).fillna(0)\n",
        "\n",
        "df_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "cd2aa276-43a1-453f-9820-eba24b738d4f",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### The dataset is very imbalanced, but we will not use smote or adasyn here to fix that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "77bf9c99-2008-4d1d-bfdf-c4f4dc3bc1f4",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "df_dataset[['isFraud', 'amount']].groupby(['isFraud']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "1724fbd7-c98c-4658-a1d0-ab8c5df609a4",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### There are some features with high correlation. \n",
        "We could have applied PCA here to reduce the # of features, but let's follow that way by now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e0cb9d3e-8b45-4165-b7a5-627dc4501fff",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "corr = df_dataset.corr()\n",
        "\n",
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\"f\",\n",
        "            xticklabels=corr.columns.values,\n",
        "            yticklabels=corr.columns.values,\n",
        "            ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "1b9674f0-0996-4a50-9aa3-9fc11e1a51ff",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### Now, we can select some features and generate the dataset\n",
        "After a few rounds of training/testing and optimization, SHAP was applied to help us to select the best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "876e6fca-7f66-40f7-914a-ddcee2f8697f",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "df_train = df_dataset[[\n",
        "    'isFraud', 'type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',    \n",
        "    'newbalanceDest', 'hour', 'dayOfMonth', 'isMerchantDest',\n",
        "        'errorBalanceOrig', 'errorBalanceDest' \n",
        "]].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Register the dataset in the Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "\n",
        "workspace = Workspace.from_config()\n",
        "datastore = Datastore.get(workspace, 'workspaceblobstore')\n",
        "dataset = Dataset.Tabular.register_pandas_dataframe(df_train, datastore, \"train-data\", show_progress=True)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "1 - Fraud Detection - Data Preparation",
      "notebookOrigID": 3502448674513988,
      "widgets": {}
    },
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
